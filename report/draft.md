# 주제
1. SLAM과 내비게이션을 할 때 물리적인 기기와 화면상에 동기화되는 기기가 서로 반대로 움직이는 문제
2. 터틀봇의 인식 범위 및 정확도에 대한 연구: 만약 카메라 사용이 가능하다면 객체 인식과 결합해서 터틀봇이 인지하지 못한 장애물을 카메라로 추가 인식? -> 후속 연구
3. 터틀봇 라이더의 상하 감지 범위 측정

# 할 일
측정하기

# 실험 설계
* 라이더와 오브젝트의 거리에 따른 인식 가능 범위 측정

준비물  
오브젝트로 사용할 물체: 박스테이프 너비 정도로 얇고 긴 것

실험 방법 2가지
1. 물리적인 공간에서 직접 이동 -> 채택
2. 가제보 시뮬레이션 -> 현재 성공 전적 없음, 시뮬레이션으로 돌려도 바퀴는 돌아가므로 기기를 땅에서 살짝 떼놓아야 함

# 연습 기록
* SLAM 사용시 인위적인 기기 이동이 잦을수록 지도가 망가짐
* 기기의 이동 속도가 너무 빠를 경우 지도 업데이트가 느려 지도 상 기기 위치가 제대로 연동되지 않을 수 있음
* 주변 지형에 틈이 너무 많을 경우 지도가 제대로 나와도 사람이 알아보기 어려움: 터틀봇 앞에 박스가 올려진 끌차가 있다면 터틀봇은 그 끌차의 바퀴만 인식할 수 있었음. 실제로는 터틀봇은 그 끌차 밑으로 지나갈 수 없음. 터틀봇 정수리보다 끌차가 낮았음.
* 투명한 판은 인식하지 못함

# 시도해볼 수 있는 것
* 어차피 가상 기기가 반대로 간다면 사람도 내비게이션 위치 조정 시 반대로 세팅하면 되지 않을까?
* 통제된 환경에서 다시 테스트해볼 필요가 있다.

# 희망사항
카메라 세팅해서 켜보기: 자율 주행 튜토리얼에 세팅 방법이 있는데 어제 하다 말고 시간 다 돼서 집에 갔음